# src/desktop_ml_daemon.py
import time
import tempfile
import subprocess
from pathlib import Path
from typing import List, Dict, Any

import requests
import torch
from torchvision import transforms
from PIL import Image

from model_def import MultiLabelTagModel

# =======================
# ì„¤ì • ë¶€ë¶„
# =======================

# ğŸ”¥ ë°±ì—”ë“œ ì£¼ì†Œ (ì§€ê¸ˆ ì“°ëŠ” 10.10.10.2:11002)
BACKEND_BASE_URL = "http://10.10.10.2:11002"

PENDING_API_URL = f"{BACKEND_BASE_URL}/api/videos/features/pending-desktop"
AUTO_TAG_API_URL = f"{BACKEND_BASE_URL}/api/videos/features/auto-tags"
STREAM_URL_TEMPLATE = f"{BACKEND_BASE_URL}/api/videos/{{video_no}}/stream"

BASE_DIR = Path(__file__).resolve().parent.parent
MODEL_PATH = BASE_DIR / "models" / "multilabel_tags_v1.pt"

IMAGE_SIZE = 224
BATCH_SIZE = 64
PRESENT_THRESHOLD = 0.4

# ffmpegê°€ PATHì— ë“±ë¡ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëƒ¥ "ffmpeg"
# ì•„ë‹ˆë©´ ì˜ˆ: r"C:\ffmpeg\bin\ffmpeg.exe" ë¡œ ë°”ê¿”ì¤˜
FFMPEG_PATH = "ffmpeg"

# ì£¼ê¸° (ì´ˆ) - í•  ì¼ ì—†ì„ ë•Œ ëŒ€ê¸° ì‹œê°„
POLL_INTERVAL_SEC = 30


# =======================
# ê¸°ë³¸ ì „ì²˜ë¦¬ & ëª¨ë¸ ë¡œë“œ
# =======================

def get_transform():
    return transforms.Compose([
        transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225],
        ),
    ])


def load_model(model_path: str, device: torch.device):
    ckpt = torch.load(model_path, map_location=device)

    label_names: List[str] = ckpt["label_names"]
    num_labels = len(label_names)

    model = MultiLabelTagModel(num_labels=num_labels)
    model.load_state_dict(ckpt["model_state_dict"])
    model.to(device)
    model.eval()

    return model, label_names


def predict_for_frames_dir(
    frames_dir: Path,
    model: MultiLabelTagModel,
    label_names: List[str],
    device: torch.device,
) -> Dict[str, Any]:
    """
    frames_dir ì•„ë˜ì˜ ëª¨ë“  JPG/PNG í”„ë ˆì„ì„ ì½ì–´ì„œ
    - ëª¨ë¸ì— ë°°ì¹˜ë¡œ ë„£ê³ 
    - í”„ë ˆì„ë³„ í™•ë¥  í‰ê·  â†’ ì˜ìƒ ë‹¨ìœ„ í™•ë¥ 
    - top3 / present_tags / all_scores ë°˜í™˜
    """
    tf = get_transform()

    img_paths = sorted(
        [p for p in frames_dir.iterdir()
         if p.suffix.lower() in [".jpg", ".jpeg", ".png"]]
    )

    if not img_paths:
        raise ValueError(f"í”„ë ˆì„ì´ ì—†ìŠµë‹ˆë‹¤: {frames_dir}")

    all_probs = []

    for start in range(0, len(img_paths), BATCH_SIZE):
        batch_paths = img_paths[start:start + BATCH_SIZE]

        batch_imgs = []
        for p in batch_paths:
            img = Image.open(p).convert("RGB")
            x = tf(img)
            batch_imgs.append(x)

        x = torch.stack(batch_imgs, dim=0).to(device)

        with torch.no_grad():
            logits = model(x)
            probs = torch.sigmoid(logits)

        all_probs.append(probs.cpu())

    probs_all = torch.cat(all_probs, dim=0)   # (F, L)
    probs_video = probs_all.mean(dim=0).numpy()  # (L,)

    sorted_idx = probs_video.argsort()[::-1]

    top3 = []
    for i in range(3):
        idx = sorted_idx[i]
        name = label_names[idx]
        score = float(probs_video[idx])
        top3.append({"name": name, "score": score})

    present_tags = []
    for i, name in enumerate(label_names):
        score = float(probs_video[i])
        if score >= PRESENT_THRESHOLD:
            present_tags.append({"name": name, "score": score})

    all_scores = {
        label_names[i]: float(probs_video[i])
        for i in range(len(label_names))
    }

    return {
        "top3": top3,
        "present_tags": present_tags,
        "all_scores": all_scores,
        "frame_count": int(probs_all.shape[0]),
    }


# =======================
# ë°±ì—”ë“œì™€ í†µì‹  ê´€ë ¨ í•¨ìˆ˜
# =======================

def fetch_pending(limit: int = 3) -> List[Dict[str, Any]]:
    """
    ì•„ì§ DESKTOP_ML íƒœê·¸ê°€ ì—†ëŠ” ìŠ¹ì¸ëœ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    """
    resp = requests.get(PENDING_API_URL, params={"limit": limit}, timeout=10)
    resp.raise_for_status()
    data = resp.json()
    if not isinstance(data, list):
        return []
    return data


def download_video(video_no: int, download_dir: Path) -> Path:
    """
    ë°±ì—”ë“œ ìŠ¤íŠ¸ë¦¼ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
    """
    url = STREAM_URL_TEMPLATE.format(video_no=video_no)
    print(f"[WORKER] ì˜ìƒ ë‹¤ìš´ë¡œë“œ: {url}")

    resp = requests.get(url, stream=True, timeout=60)
    resp.raise_for_status()

    # í™•ì¥ìëŠ” ffmpeg ì…ì¥ì—ì„  í¬ê²Œ ì¤‘ìš”í•˜ì§€ ì•Šì•„ì„œ .mp4 ë¡œ í†µì¼
    video_path = download_dir / f"{video_no}.mp4"
    with open(video_path, "wb") as f:
        for chunk in resp.iter_content(8192):
            if chunk:
                f.write(chunk)

    return video_path


def extract_frames_with_ffmpeg(video_path: Path, frames_dir: Path) -> None:
    """
    ffmpeg ë¥¼ ì´ìš©í•´ 1ì´ˆë‹¹ 1í”„ë ˆì„ ìº¡ì²˜
    """
    frames_dir.mkdir(parents=True, exist_ok=True)
    out_pattern = str(frames_dir / "frame-%03d.jpg")

    cmd = [
        FFMPEG_PATH,
        "-y",
        "-i",
        str(video_path),
        "-vf",
        "fps=1",
        out_pattern,
    ]

    print(f"[WORKER] ffmpeg ì‹¤í–‰: {' '.join(cmd)}")
    proc = subprocess.run(
        cmd,
        stdout=subprocess.PIPE,
        stderr=subprocess.PIPE,
    )

    if proc.returncode != 0:
        err_msg = proc.stderr.decode(errors="ignore")
        raise RuntimeError(f"ffmpeg ì‹¤íŒ¨ (code={proc.returncode}): {err_msg}")


def build_payload(video_no: int, result: Dict[str, Any]) -> Dict[str, Any]:
    """
    VideoAutoTagRequest í˜•ì‹ì— ë§ëŠ” payload ìƒì„±
    """
    top3 = result.get("top3", [])
    payload = {
        "videoNo": video_no,
        "mainTag": top3[0] if top3 else None,
        "subTags": top3[1:] if len(top3) > 1 else [],
        "presentTags": result.get("present_tags", []),
        "allScores": result.get("all_scores", {}),
        "frameCount": result.get("frame_count", 0),
    }
    return payload


def post_auto_tags(payload: Dict[str, Any]) -> None:
    """
    ë°±ì—”ë“œ /api/videos/features/auto-tags ë¡œ íƒœê·¸ ì „ì†¡
    """
    resp = requests.post(AUTO_TAG_API_URL, json=payload, timeout=30)
    print(f"[WORKER] íƒœê·¸ ì „ì†¡ ì‘ë‹µ ì½”ë“œ: {resp.status_code}")
    resp.raise_for_status()


# =======================
# ê°œë³„ ì˜ìƒ ì²˜ë¦¬
# =======================

def process_one_video(
    video_no: int,
    model: MultiLabelTagModel,
    label_names: List[str],
    device: torch.device,
):
    print(f"[WORKER] ===== ì˜ìƒ {video_no} ì²˜ë¦¬ ì‹œì‘ =====")

    # ì„ì‹œ ë””ë ‰í„°ë¦¬ í•˜ë‚˜ ë§Œë“¤ì–´ì„œ ê·¸ ì•ˆì— ì˜ìƒ + í”„ë ˆì„ ì €ì¥
    with tempfile.TemporaryDirectory(prefix=f"video_{video_no}_") as tmpdir:
        tmp_dir = Path(tmpdir)

        # 1) ì˜ìƒ ë‹¤ìš´ë¡œë“œ
        video_path = download_video(video_no, tmp_dir)

        # 2) ffmpeg ë¡œ í”„ë ˆì„ ì¶”ì¶œ
        frames_dir = tmp_dir / "frames"
        extract_frames_with_ffmpeg(video_path, frames_dir)

        # 3) ë¡œì»¬ ëª¨ë¸ë¡œ ë©€í‹°ë¼ë²¨ íƒœê¹…
        result = predict_for_frames_dir(
            frames_dir=frames_dir,
            model=model,
            label_names=label_names,
            device=device,
        )

        # 4) payload ë§Œë“¤ê³  ë°±ì—”ë“œì— ì „ì†¡
        payload = build_payload(video_no, result)
        print("[WORKER] íƒœê·¸ payload:", payload)

        post_auto_tags(payload)

    print(f"[WORKER] ===== ì˜ìƒ {video_no} ì²˜ë¦¬ ì™„ë£Œ =====")


# =======================
# ë©”ì¸ ë£¨í”„
# =======================

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("ì‚¬ìš© ì¥ì¹˜:", device)

    model, label_names = load_model(str(MODEL_PATH), device)

    print("[WORKER] ë°ìŠ¤í¬íƒ‘ ML ë°ëª¬ ì‹œì‘")
    print("[WORKER] ë°±ì—”ë“œ:", BACKEND_BASE_URL)
    print("[WORKER] ëª¨ë¸ ê²½ë¡œ:", MODEL_PATH)

    while True:
        try:
            pending_list = fetch_pending(limit=3)
        except Exception as e:
            print("[WORKER] pending ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨:", e)
            time.sleep(POLL_INTERVAL_SEC)
            continue

        if not pending_list:
            # ì²˜ë¦¬í•  ì˜ìƒì´ ì—†ìœ¼ë©´ ì ê¹ ì‰¼
            print(f"[WORKER] ì²˜ë¦¬í•  ì˜ìƒ ì—†ìŒ. {POLL_INTERVAL_SEC}ì´ˆ ëŒ€ê¸°...")
            time.sleep(POLL_INTERVAL_SEC)
            continue

        print(f"[WORKER] ì²˜ë¦¬í•  ì˜ìƒ ëª©ë¡: {[p['videoNo'] for p in pending_list]}")

        for item in pending_list:
            video_no = int(item.get("videoNo"))
            try:
                process_one_video(video_no, model, label_names, device)
            except Exception as e:
                print(f"[WORKER] ì˜ìƒ {video_no} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜:", e)

        # í•œ ë²ˆ ë‹¤ ëŒë¦¬ê³  ì ê¹ ì‰° ë’¤ ë‹¤ìŒ ë£¨í”„ë¡œ
        time.sleep(3)


if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n[WORKER] ì¢…ë£Œ ìš”ì²­ ê°ì§€. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
